{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def enhance_image(image):\n",
    "    image_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCR_CB)\n",
    "    Y, Cr, Cb = cv2.split(image_YCrCb)\n",
    "    Y = cv2.equalizeHist(Y)\n",
    "    image_YCrCb = cv2.merge([Y, Cr, Cb])\n",
    "    image = cv2.cvtColor(image_YCrCb, cv2.COLOR_YCR_CB2BGR)\n",
    "    return image\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "#face_detector = dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")\n",
    "def scale_faces(face_rects, down_scale=1.5):\n",
    "    faces = []\n",
    "    for face in face_rects:\n",
    "        scaled_face = dlib.rectangle(int(face.left() * down_scale),\n",
    "                                    int(face.top() * down_scale),\n",
    "                                    int(face.right() * down_scale),\n",
    "                                    int(face.bottom() * down_scale))\n",
    "        faces.append(scaled_face)\n",
    "    return faces\n",
    "def detect_faces(image, down_scale=1.5):\n",
    "    image_scaled = cv2.resize(image, None, fx=1.0/down_scale, fy=1.0/down_scale, \n",
    "                              interpolation=cv2.INTER_LINEAR)\n",
    "    faces = face_detector(image_scaled, 0)\n",
    "  #  faces = [face.rect for face in faces]\n",
    "    faces = scale_faces(faces, down_scale)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image = cv2.imread(\"A.jpg\")\n",
    "    faces = detect_faces(image, down_scale=0.5)\n",
    "    for face in faces:\n",
    "        x,y,w,h = face.left(), face.top(), face.right(), face.bottom()\n",
    "        cv2.rectangle(image, (x,y), (w,h), (255,200,150), 2, cv2.CV_AA)\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def extract_face_embeddings(image, face_rect,shape_predictor,face_recognizer):\n",
    "    shape = shape_predictor(image, face_rect)\n",
    "    face_embedding = face_recognizer.compute_face_descriptor(image, shape)\n",
    "    face_embedding = [x for x in face_embedding]\n",
    "    face_embedding = np.array(face_embedding, dtype=\"float32\")[np.newaxis, :]\n",
    "    return face_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle\n",
    "def add_embeddings(embedding, label, \n",
    "                   embeddings_path=\"face_embeddings.npy\", \n",
    "                   labels_path=\"labels.pickle\"):\n",
    "    first_time = False\n",
    "    try:\n",
    "        embeddings = np.load(embeddings_path)\n",
    "        labels = cPickle.load(open(labels_path))\n",
    "    except IOError:\n",
    "        first_time = True\n",
    "    if first_time:\n",
    "        embeddings = embedding\n",
    "        labels = [label]\n",
    "    else:\n",
    "        embeddings = np.concatenate([embeddings, embedding], axis=0)\n",
    "        labels.append(label)\n",
    "    np.save(embeddings_path, embeddings)\n",
    "    with open(labels_path, \"w\") as f:\n",
    "        cPickle.dump(labels, f)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extractors import extract_face_embeddings\n",
    "from detectors import detect_faces\n",
    "from db import add_embeddings\n",
    "import dlib\n",
    "shape_predictor = dlib.shape_predictor(\"models/shape_predictor_5_face_landmarks.dat\")\n",
    "face_recognizer = dlib.face_recognition_model_v1(\"models/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "def enroll_face(image, label,\n",
    "                embeddings_path=\"face_embeddings.npy\",\n",
    "                labels_path=\"labels.pickle\", down_scale=1.0):\n",
    "    faces = detect_faces(image, down_scale)\n",
    "    if len(faces)<1:\n",
    "        return False\n",
    "    if len(faces)>1:\n",
    "        raise ValueError(\"Multiple faces not allowed for enrolling\")\n",
    "    face = faces[0]\n",
    "    face_embeddings = extract_face_embeddings(image, face, shape_predictor, \n",
    "                                              face_recognizer)\n",
    "    add_embeddings(face_embeddings, label, embeddings_path=embeddings_path,\n",
    "                   labels_path=labels_path)\n",
    "    return True\n",
    "if __name__ == \"__main__\":\n",
    "    import cv2\n",
    "    import glob\n",
    "    import argparse\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-d\",\"--dataset\", help=\"Path to dataset to enroll\", required=True)\n",
    "    ap.add_argument(\"-e\",\"--embeddings\", help=\"Path to save embeddings\",\n",
    "                    default=\"face_embeddings.npy\")\n",
    "    ap.add_argument(\"-l\",\"--labels\", help=\"Path to save labels\",\n",
    "                    default=\"labels.cpickle\")\n",
    "    args = vars(ap.parse_args())\n",
    "    filetypes = [\"png\", \"jpg\"]\n",
    "    dataset = args[\"dataset\"].rstrip(\"/\")\n",
    "    imPaths = []\n",
    "    for filetype in filetypes:\n",
    "        imPaths += glob.glob(\"{}/*/*.{}\".format(dataset, filetype))\n",
    "    for path in imPaths:\n",
    "        label = path.split(\"/\")[-2]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        enroll_face(image, label, embeddings_path=args[\"embeddings\"],\n",
    "                    labels_path=args[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def recognize_face(embedding, embeddings, labels, threshold=0.5):\n",
    "    distances = np.linalg.norm(embeddings - embedding, axis=1)\n",
    "    argmin = np.argmin(distances)\n",
    "    minDistance = distances[argmin]\n",
    "    if minDistance>threshold:\n",
    "        label = \"Unknown\"\n",
    "    else:\n",
    "        label = labels[argmin]\n",
    "    return (label, minDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import cv2\n",
    "    import argparse\n",
    "    from detectors import detect_faces\n",
    "    from extractors import extract_face_embeddings\n",
    "    import cPickle\n",
    "    import dlib\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-i\",\"--image\", help=\"Path to image\", required=True)\n",
    "    ap.add_argument(\"-e\",\"--embeddings\", help=\"Path to saved embeddings\",\n",
    "                    default=\"face_embeddings.npy\")\n",
    "    ap.add_argument(\"-l\", \"--labels\", help=\"Path to saved labels\",\n",
    "                    default=\"labels.pickle\")\n",
    "    args = vars(ap.parse_args())\n",
    "    embeddings = np.load(args[\"embeddings\"])\n",
    "    labels = cPickle.load(open(args[\"labels\"]))\n",
    "    shape_predictor = dlib.shape_predictor(\"models/\"\n",
    "                                           \"shape_predictor_5_face_landmarks.dat\")\n",
    "    face_recognizer = dlib.face_recognition_model_v1(\"models/\"\n",
    "                                           \"dlib_face_recognition_resnet_model_v1.dat\")\n",
    "    image = cv2.imread(args[\"image\"])\n",
    "    image_original = image.copy()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    faces = detect_faces(image)\n",
    "    for face in faces:\n",
    "        embedding = extract_face_embeddings(image, face, shape_predictor, face_recognizer)\n",
    "        label = recognize_face(embedding, embeddings, labels)\n",
    "        (x1, y1, x2, y2) = face.left(), face.top(), face.right(), face.bottom()\n",
    "        cv2.rectangle(image_original, (x1, y1), (x2, y2), (255, 120, 120), 2, cv2.CV_AA)\n",
    "        cv2.putText(image_original, label[0], (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "    cv2.imshow(\"Image\", image_original)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-628a7d44ecf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mminifinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Downloads\\innovation\\innovation\\minifinal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import minifinal.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "hand = cv2.imread('Capture.png',0)\n",
    "\n",
    "ret, the = cv2.threshold(hand, 70, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "_,contours,_ = cv2.findContours(the.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "hull = [cv2.convexHull(c) for c in contours]\n",
    "final = cv2.drawContours(hand, hull, -1, (255,0,0))\n",
    "\n",
    "cv2.imshow('Originals', hand)\n",
    "cv2.imshow('Thresh',the)\n",
    "cv2.imshow('Convex hull',final)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
